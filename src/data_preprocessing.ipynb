{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:02:17.403907Z",
     "start_time": "2022-10-26T18:02:12.198684Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read log data\n",
    "with open('../raw data/training-log-corpus.log', 'r') as f:\n",
    "    logs = f.readlines()\n",
    "\n",
    "last_time = 0.0\n",
    "last_student = ''\n",
    "action_count = 0\n",
    "l = []\n",
    "for i, line in enumerate(logs):\n",
    "    tokens = line.split('\\n')[0]\n",
    "    tokens = tokens.split('|')\n",
    "\n",
    "    student_id = tokens[0]\n",
    "    if len(student_id) != 8:\n",
    "        print(\n",
    "            f\"ERROR: in line {i}, student id length should be 8, found {len(student_id)}!\"\n",
    "        )\n",
    "        exit(0)\n",
    "\n",
    "    action = tokens[1]\n",
    "\n",
    "    # starting entries do not have time\n",
    "    try:\n",
    "        float(tokens[2])\n",
    "    except:\n",
    "        tokens.insert(2, 0.0)\n",
    "    time = float(tokens[2])\n",
    "\n",
    "    if last_student != student_id:\n",
    "        last_time = 0.0\n",
    "        print(f\"{action_count} actions found for student {last_student}\")\n",
    "        action_count = 0\n",
    "\n",
    "    # check is time is almost monotonic\n",
    "    if last_time - time >= 1:\n",
    "        print(\n",
    "            f\"ERROR: in line {i}, time is not monotonic! current action {action}. total action found {action_count}. student {student_id}\"\n",
    "        )\n",
    "\n",
    "    last_time = time\n",
    "    last_student = student_id\n",
    "    action_count += 1\n",
    "\n",
    "    try:\n",
    "        detail = tokens[3]\n",
    "    except:\n",
    "        detail = \"\"\n",
    "\n",
    "    others = (\"|\").join(tokens[4:])\n",
    "\n",
    "    l.append({\n",
    "        'student_id': student_id,\n",
    "        'action': action,\n",
    "        'time': time,\n",
    "        'detail': detail,\n",
    "        'others': others\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(l,\n",
    "                  columns=['student_id', 'action', 'time', 'detail', 'others'])\n",
    "\n",
    "\n",
    "# for students with \"RESET\"\n",
    "# we are keeping if student reseted after planing signifcant part of the game (>70%)\n",
    "# or resetted very early (<30%)\n",
    "print(\"-- removing reset issues --\")\n",
    "dlt_idx = []\n",
    "student_with_reset = df.loc[df['action'] == 'RESET']['student_id'].unique()\n",
    "for student in student_with_reset:\n",
    "    df_s = df.loc[df['student_id'] == student]\n",
    "    total_steps = len(df_s)\n",
    "    i = df.loc[(df['student_id'] == student)\n",
    "               & (df['action'] == 'RESET')].index[0]\n",
    "    before_reset_steps = len(df_s.loc[:i])\n",
    "    percent_before_reset = round(before_reset_steps / total_steps * 100, 2)\n",
    "    drop_curr = []\n",
    "    if percent_before_reset < 30.0:\n",
    "        drop_curr = list(df_s.loc[df_s.index[0]:i + 1].index)\n",
    "    elif percent_before_reset > 70.0:\n",
    "        drop_curr = list(df_s.loc[i:].index)\n",
    "    else:\n",
    "        drop_curr = list(df_s.index)\n",
    "\n",
    "    print(\n",
    "        \"student: {0} | total_steps: {1} | reset_at: {2}({3}%) | dropping: {4}\"\n",
    "        .format(student, total_steps, before_reset_steps, percent_before_reset,\n",
    "                len(drop_curr)))\n",
    "    dlt_idx += drop_curr\n",
    "    \n",
    "\n",
    "df = df.drop(index=dlt_idx).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:02:17.430241Z",
     "start_time": "2022-10-26T18:02:17.409430Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# creating action to feature maps\n",
    "action_map = {\n",
    "    'DIALOG': 's_dialog_turn',\n",
    "    'OPEN': 's_open_door',\n",
    "    'LOOKSTART': 's_view_poster',\n",
    "    'PICKUP': 's_pickup_obj',\n",
    "    'DROP': 's_drop_obj',\n",
    "    'TESTOBJECT': 's_test_obj',\n",
    "    'WORKSHEET': 's_worksheet',\n",
    "    'QUIZ': 's_quiz',\n",
    "    'PDAOPEN': 's_use_pda',\n",
    "    'LABELING': 's_label_slide',\n",
    "    'NOTES': 's_take_note',\n",
    "    'BOOKREAD': 's_read_book',\n",
    "    'BRYCECOMPUTER': 's_bryce_computer',\n",
    "    'GAMEOVER': 's_end_game'\n",
    "}\n",
    "\n",
    "# TALK action needs to be segmented further for narrative planner\n",
    "action_talk_map = {\n",
    "    'cur-action-talk-bryce': 's_talk_bryce',\n",
    "    'cur-action-talk-teresa': 's_talk_teresa', \n",
    "    'cur-action-talk-ford': 's_talk_ford_quen_rob', \n",
    "    'cur-action-talk-quentin': 's_talk_ford_quen_rob', \n",
    "    'cur-action-talk-robert': 's_talk_ford_quen_rob', \n",
    "    \n",
    "    'cur-action-talk-extraa': 's_talk_others',\n",
    "    'cur-action-talk-extrab': 's_talk_others',\n",
    "    'cur-action-talk-elise': 's_talk_others',\n",
    "    'cur-action-talk-kim': 's_talk_others',\n",
    "    \n",
    "}\n",
    "\n",
    "# all types of adaptions. Not using mystry quiz (as this has 8 choise) and off-task behavior (not enough sample)\n",
    "adaption_map = {\n",
    "    'select-bryce-symptoms-level': 's_aes_bryce_symptoms',\n",
    "    'select-teresa-symptoms-level': 's_aes_teresa_symptoms',\n",
    "    'select-present-quiz': 's_aes_knowledge_quiz',\n",
    "    'select-worksheet-level': 's_aes_diagnosis_feedback',\n",
    "}\n",
    "\n",
    "# start index of action triggers \n",
    "narrative_trigger_map = {\n",
    "    's_aes_trigger_bryce_symptoms': -1, # two actions [0, 1] \n",
    "    's_aes_trigger_teresa_symptoms': 1, # three actions [2, 3, 4]\n",
    "    's_aes_trigger_knowledge_quiz': 4, # two actions [5, 6]\n",
    "    's_aes_trigger_diagnosis_feedback': 6 # three actions [7, 8, 9],\n",
    "}\n",
    "\n",
    "narrative_trigger_map_for_env = {\n",
    "    0: ['s_aes_bryce_symptoms', 1],\n",
    "    1: ['s_aes_bryce_symptoms', 2],\n",
    "    2: ['s_aes_teresa_symptoms', 1],\n",
    "    3: ['s_aes_teresa_symptoms', 2],\n",
    "    4: ['s_aes_teresa_symptoms', 3],\n",
    "    5: ['s_aes_knowledge_quiz', 1],\n",
    "    6: ['s_aes_knowledge_quiz', 2],\n",
    "    7: ['s_aes_diagnosis_feedback', 1],\n",
    "    8: ['s_aes_diagnosis_feedback', 2],\n",
    "    9: ['s_aes_diagnosis_feedback', 3]\n",
    "}\n",
    "\n",
    "student_trigger_map = {}\n",
    "act_num = 0\n",
    "for state in set(action_map.values()):\n",
    "    student_trigger_map[state] = act_num\n",
    "    act_num += 1\n",
    "for state in set(action_talk_map.values()):\n",
    "    student_trigger_map[state] = act_num\n",
    "    act_num += 1\n",
    "student_trigger_map['s_worksheet_submitted'] = act_num\n",
    "\n",
    "states_student = list(student_trigger_map.keys()) + list(adaption_map.values())\n",
    "init_row_student = defaultdict()\n",
    "for state in states_student:\n",
    "    init_row_student[state] = 0 \n",
    "    \n",
    "states_narrative = list(student_trigger_map.keys()) + list(adaption_map.values()) + list(narrative_trigger_map.keys())\n",
    "init_row_narrative = defaultdict()\n",
    "for state in states_narrative:\n",
    "    init_row_narrative[state] = 0 \n",
    "\n",
    "print(student_trigger_map)\n",
    "print(states_narrative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do we need SOLUTION for s_aes_mystry_solution?\n",
    "- kim revel adaption points player towards quentin's revel\n",
    "- removing students who did restart. maybe worthwhile to include them later \n",
    "- 21 students didn't do pretest. thus nlg none. removing them. maybe worthwhile to include them later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:02:48.703700Z",
     "start_time": "2022-10-26T18:02:17.434002Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pdb\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "skipping_action = set()\n",
    "skipping_adaption = set()\n",
    "\n",
    "all_inserts_student = []\n",
    "all_inserts_narrative = []\n",
    "for student_id, rows in df.groupby(['student_id']):\n",
    "    row_insert_student = deepcopy(init_row_student)\n",
    "    row_insert_student['student_id'] = student_id\n",
    "    row_insert_student['step'] = 0\n",
    "    row_insert_student['done'] = False\n",
    "    \n",
    "    # this part is for narrative df only\n",
    "    latest_adaptive_trigger = ''\n",
    "    step_narrative = 0\n",
    "    \n",
    "    for i, row in rows.iterrows():\n",
    "        if row['action'] == 'ADAPTATION':\n",
    "            if row['detail'] not in adaption_map.keys():\n",
    "                skipping_adaption.add(row['detail'])\n",
    "                continue\n",
    "\n",
    "            for adapt_feature in adaption_map.values():\n",
    "                row_insert_student[adapt_feature] = 0\n",
    "\n",
    "            row_insert_student[adaption_map[row['detail']]] = int(row['others'][-1:])\n",
    "            \n",
    "            # this part is for narrative df only\n",
    "            \n",
    "            # no adaption (among the selected ones) can happen as first action. \n",
    "            # thus, there must be another state before \n",
    "            row_insert_narrative = deepcopy(all_inserts_student[-1])\n",
    "            for adapt_trigger_feature in narrative_trigger_map.keys():\n",
    "                row_insert_narrative[adapt_trigger_feature] = 0\n",
    "            row_insert_narrative[latest_adaptive_trigger] = 1\n",
    "#             row_insert_narrative['step'] = step_narrative\n",
    "            \n",
    "            # converting different AES actions into uniform actions\n",
    "            row_insert_narrative['action'] = narrative_trigger_map[latest_adaptive_trigger] + int(row['others'][-1:])\n",
    "            row_insert_narrative['action_name'] = latest_adaptive_trigger + '_' +str(int(row['others'][-1:]))\n",
    "            step_narrative += 1\n",
    "            all_inserts_narrative.append(deepcopy(row_insert_narrative))\n",
    "            continue\n",
    "\n",
    "        if row['action'] == 'TALK':\n",
    "            char = row['others'].split('|')[0]\n",
    "            if char not in action_talk_map.keys():\n",
    "                print(\n",
    "                    \"-- ERROR TALK UNKNOWN | action: {0} | detail: {1} | others: {2} --\"\n",
    "                    .format(row['action'], row['detail'], row['others']))\n",
    "                break\n",
    "            row_insert_student[action_talk_map[char]] += 1\n",
    "            action = action_talk_map[char]\n",
    "        \n",
    "        elif row['action'] == 'DIALOG':\n",
    "            if row['detail'] == 'menu-choice':\n",
    "                if row['others'].split('|')[-1] == 'IthinkIhaveadiagnosis':\n",
    "                    row_insert_student['s_worksheet_submitted'] += 1\n",
    "                    action = 's_worksheet_submitted'\n",
    "                else:\n",
    "                    row_insert_student[action_map[row['action']]] += 1\n",
    "                    action = action_map[row['action']]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        elif row['action'] in action_map.keys():\n",
    "            row_insert_student[action_map[row['action']]] += 1\n",
    "            action = action_map[row['action']]\n",
    "        else:\n",
    "            skipping_action.add(row['action'])\n",
    "            if row['action'] == 'RESET':\n",
    "                print(\n",
    "                    \"-- ERROR RESET happened for student {0} --\".format(student_id))\n",
    "            continue\n",
    "\n",
    "        row_insert_student['action'] = student_trigger_map[action]\n",
    "        row_insert_student['action_name'] = action\n",
    "        all_inserts_student.append(deepcopy(row_insert_student))\n",
    "        row_insert_student['step'] += 1\n",
    "        \n",
    "        if action == 's_end_game':\n",
    "            break\n",
    "        \n",
    "        \n",
    "        # this part is for narrative df only\n",
    "        if action == 's_talk_bryce':\n",
    "            latest_adaptive_trigger = 's_aes_trigger_bryce_symptoms'\n",
    "        elif action == 's_talk_teresa':\n",
    "            latest_adaptive_trigger = 's_aes_trigger_teresa_symptoms'\n",
    "        elif action == 's_talk_ford_quen_rob':\n",
    "            latest_adaptive_trigger = 's_aes_trigger_knowledge_quiz'\n",
    "        elif action == 's_worksheet_submitted':\n",
    "            latest_adaptive_trigger = 's_aes_trigger_diagnosis_feedback'\n",
    "    \n",
    "    if all_inserts_student[-1]['action_name'] != 's_end_game':\n",
    "        row_insert_student['s_eng_game'] = 1\n",
    "        row_insert_student['step'] += 1\n",
    "        row_insert_student['action'] = student_trigger_map['s_end_game']\n",
    "        row_insert_student['action_name'] = 's_end_game'\n",
    "        all_inserts_student.append(deepcopy(row_insert_student))\n",
    "            \n",
    "    all_inserts_student[-1]['done'] = True\n",
    "    all_inserts_narrative[-1]['done'] = True\n",
    "\n",
    "    print('-- finished student {0} --'.format(student_id))\n",
    "\n",
    "df_student_data = pd.DataFrame(all_inserts_student,\n",
    "                               columns=['student_id', 'step'] + states_student +\n",
    "                               ['action', 'action_name', 'done'])\n",
    "\n",
    "df_narrative_data = pd.DataFrame(all_inserts_narrative,\n",
    "                               columns=['student_id', 'step'] + states_narrative +\n",
    "                               ['action', 'action_name', 'done'])\n",
    "\n",
    "\n",
    "print(\"Actions skipped\", skipping_action)\n",
    "print(\"Adaptions skipped\", skipping_adaption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:02:48.902516Z",
     "start_time": "2022-10-26T18:02:48.706879Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merging scores in the feature list\n",
    "\n",
    "df_score = pd.read_csv('../raw data/training-survey-corpus.csv')\n",
    "df_score = df_score[[\n",
    "    'Student ID', 'Gender', 'Game-Playing Frequency', 'Content Pre Total',\n",
    "    'Normalized Learning Gain'\n",
    "]]\n",
    "df_score = df_score.rename(\n",
    "    columns={\n",
    "        'Student ID': 'student_id',\n",
    "        'Gender': 's_static_gender',\n",
    "        'Game-Playing Frequency': 's_static_game_freq',\n",
    "        'Content Pre Total': 's_static_pretest',\n",
    "        'Normalized Learning Gain': 'reward'\n",
    "    })\n",
    "\n",
    "# few reward are NONE!\n",
    "df_score = df_score.loc[df_score['reward']!='None']\n",
    "df_score['reward'] = pd.to_numeric(df_score['reward'])\n",
    "\n",
    "\n",
    "# making sure we have rewards for all students\n",
    "df_student_data = df_student_data.loc[df_student_data['student_id'].isin(df_score['student_id'].unique())]\n",
    "df_student_data = df_student_data.reset_index(drop=True)\n",
    "\n",
    "df_narrative_data = df_narrative_data.loc[df_narrative_data['student_id'].isin(df_score['student_id'].unique())]\n",
    "df_narrative_data = df_narrative_data.reset_index(drop=True)\n",
    "\n",
    "df_score = df_score.loc[df_score['student_id'].isin(df_student_data['student_id'].unique())]\n",
    "\n",
    "\n",
    "# splitting reward based on median\n",
    "mid_reward = df_score['reward'].describe()['50%']\n",
    "df_score.loc[df_score['reward']<mid_reward, 'reward'] = -100\n",
    "df_score.loc[df_score['reward']>=mid_reward, 'reward'] = 100\n",
    "\n",
    "\n",
    "df_student_data = df_student_data.merge(df_score,\n",
    "                                        on=['student_id'],\n",
    "                                        how='left')\n",
    "\n",
    "df_narrative_data = df_narrative_data.merge(df_score,\n",
    "                                        on=['student_id'],\n",
    "                                        how='left')\n",
    "\n",
    "df_narrative_data.loc[df_narrative_data['done']==False, 'reward'] = 0\n",
    "df_student_data.loc[df_student_data['done']==False, 'reward'] = 0\n",
    "\n",
    "df_student_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:03:05.040083Z",
     "start_time": "2022-10-26T18:02:48.904183Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# creating states\n",
    "df_student_data['state'] = df_student_data.apply(lambda x: np.array([\n",
    "    # 0-18 position matching student action numbers\n",
    "    x['s_view_poster'],\n",
    "    x['s_label_slide'],\n",
    "    x['s_read_book'],\n",
    "    x['s_test_obj'],\n",
    "    x['s_bryce_computer'],\n",
    "    x['s_end_game'], # 5\n",
    "    x['s_take_note'],\n",
    "    x['s_drop_obj'],\n",
    "    x['s_dialog_turn'],\n",
    "    x['s_open_door'],\n",
    "    x['s_worksheet'],\n",
    "    x['s_use_pda'],\n",
    "    x['s_quiz'],\n",
    "    x['s_pickup_obj'],\n",
    "    x['s_talk_ford_quen_rob'], # 14\n",
    "    x['s_talk_bryce'], # 15\n",
    "    x['s_talk_others'], # 16\n",
    "    x['s_talk_teresa'], # 17\n",
    "    x['s_worksheet_submitted'], # 18\n",
    "    \n",
    "    # 19-22 position\n",
    "    x['s_aes_bryce_symptoms'],\n",
    "    x['s_aes_teresa_symptoms'],\n",
    "    x['s_aes_knowledge_quiz'],\n",
    "    x['s_aes_diagnosis_feedback'],\n",
    "    \n",
    "    # 23-25 position\n",
    "    x['s_static_gender'], \n",
    "    x['s_static_game_freq'], \n",
    "    x['s_static_pretest'], \n",
    "    # 26 position new\n",
    "    x['step'],\n",
    "]), axis=1)\n",
    "\n",
    "# creating states\n",
    "df_narrative_data['state'] = df_narrative_data.apply(lambda x: np.array([\n",
    "    # 0-18 position matching student action numbers\n",
    "    x['s_view_poster'],\n",
    "    x['s_label_slide'],\n",
    "    x['s_read_book'],\n",
    "    x['s_test_obj'],\n",
    "    x['s_bryce_computer'],\n",
    "    x['s_end_game'],\n",
    "    x['s_take_note'],\n",
    "    x['s_drop_obj'],\n",
    "    x['s_dialog_turn'],\n",
    "    x['s_open_door'],\n",
    "    x['s_worksheet'],\n",
    "    x['s_use_pda'],\n",
    "    x['s_quiz'],\n",
    "    x['s_pickup_obj'],\n",
    "    x['s_talk_ford_quen_rob'],\n",
    "    x['s_talk_bryce'],\n",
    "    x['s_talk_others'],\n",
    "    x['s_talk_teresa'],\n",
    "    x['s_worksheet_submitted'],\n",
    "    \n",
    "    # 19-22 position\n",
    "    x['s_aes_bryce_symptoms'],\n",
    "    x['s_aes_teresa_symptoms'],\n",
    "    x['s_aes_knowledge_quiz'],\n",
    "    x['s_aes_diagnosis_feedback'],\n",
    "    \n",
    "    # 23-25 position\n",
    "    x['s_static_gender'], \n",
    "    x['s_static_game_freq'], \n",
    "    x['s_static_pretest'],\n",
    "    # 26 position new added\n",
    "    x['step'],\n",
    "    \n",
    "    # 27-30 position\n",
    "    x['s_aes_trigger_bryce_symptoms'],\n",
    "    x['s_aes_trigger_teresa_symptoms'],\n",
    "    x['s_aes_trigger_knowledge_quiz'],\n",
    "    x['s_aes_trigger_diagnosis_feedback']\n",
    "]), axis=1)\n",
    "\n",
    "\n",
    "# df_student_data.to_pickle('../processed_data/student_trajectories.pkl')\n",
    "# df_narrative_data.to_pickle('../processed_data/narrative_trajectories.pkl')\n",
    "# df_score.to_pickle('../processed_data/scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:03:05.049331Z",
     "start_time": "2022-10-26T18:03:05.042250Z"
    }
   },
   "outputs": [],
   "source": [
    "df_student_data.apply(lambda x: x['state'][-5:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:03:05.055707Z",
     "start_time": "2022-10-26T18:03:05.051353Z"
    }
   },
   "outputs": [],
   "source": [
    "df_narrative_data.apply(lambda x: x['state'][-5:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:03:05.063955Z",
     "start_time": "2022-10-26T18:03:05.060193Z"
    }
   },
   "outputs": [],
   "source": [
    "df_student_data.to_pickle('../processed_data/student_trajectories.pkl')\n",
    "df_narrative_data.to_pickle('../processed_data/narrative_trajectories.pkl')\n",
    "df_score.to_pickle('../processed_data/scores.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T18:03:05.071428Z",
     "start_time": "2022-10-26T18:03:05.067018Z"
    }
   },
   "source": [
    "# random Tried LSTM based outcome predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-28T18:36:26.545370Z",
     "start_time": "2022-10-28T18:36:26.346425Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_all = pd.read_pickle('../processed_data/student_trajectories.pkl')\n",
    "state_dim = 8\n",
    "seq_len = 700\n",
    "\n",
    "all_states = []\n",
    "label = []\n",
    "\n",
    "for student, df in df_all.groupby('student_id'): \n",
    "    states = df.apply(lambda x: np.append(x['state'][-8:-1], np.array([x['action']])), axis=1)\n",
    "    states = np.stack(states)\n",
    "    curr_len = len(states)\n",
    "    if curr_len <= seq_len:\n",
    "        pad_len = seq_len - curr_len\n",
    "        states = np.pad(states, pad_width=[(pad_len, 0),(0, 0)], mode='constant', constant_values=0.)\n",
    "    else:\n",
    "        states = states[-seq_len:, :]\n",
    "\n",
    "    all_states.append(states)\n",
    "\n",
    "    label.append(df.iloc[-1]['reward'])\n",
    "\n",
    "label = np.array([1 if r == 100. else 0 for r in label])\n",
    "states = np.stack(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_id, test_id = train_test_split(range(len(label)), test_size=.2, stratify=label)\n",
    "\n",
    "X_train = states[train_id]\n",
    "y_train = label[train_id]\n",
    "\n",
    "y_test = label[test_id]\n",
    "valid_id, test_id = train_test_split(test_id, test_size=.5, stratify=y_test)\n",
    "X_valid = states[valid_id]\n",
    "y_valid = label[valid_id]\n",
    "\n",
    "X_test = states[test_id]\n",
    "y_test = label[test_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(X_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.LongTensor))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test).type(torch.FloatTensor), torch.from_numpy(y_test).type(torch.LongTensor))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid).type(torch.FloatTensor), torch.from_numpy(y_valid).type(torch.LongTensor))\n",
    "\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 20\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMValidator(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform prediction on high/low learning gain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size, seq_len, state_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(state_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "output_size = 1\n",
    "seq_len = 700\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "net = LSTMValidator(output_size, seq_len, state_dim, hidden_dim, n_layers, drop_prob=0.5)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "counter = 0\n",
    "print_every = 1\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        if len(inputs) < batch_size:\n",
    "            print('skipping {0} inputs in train'.format(len(inputs)))\n",
    "            continue\n",
    "        counter += 1\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "#         inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                if len(inputs) < batch_size:\n",
    "                    print('skipping {0} inputs in valid'.format(len(inputs)))\n",
    "                    continue\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) \n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3038, 7496)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_org = pd.read_pickle('../processed_data/narrative_trajectories.pkl')\n",
    "df_sim = pd.read_pickle('../simulated_data/seed_0_sim_narr.pkl')\n",
    "len(df_org), len(df_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(398, 1000)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_org['student_id'].unique()), len(df_sim['student_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['student_id', 'step', 's_use_pda', 's_drop_obj', 's_test_obj',\n       's_take_note', 's_end_game', 's_pickup_obj', 's_quiz',\n       's_bryce_computer', 's_view_poster', 's_label_slide', 's_dialog_turn',\n       's_worksheet', 's_read_book', 's_open_door', 's_talk_others',\n       's_talk_bryce', 's_talk_ford_quen_rob', 's_talk_teresa',\n       's_worksheet_submitted', 's_aes_bryce_symptoms',\n       's_aes_teresa_symptoms', 's_aes_knowledge_quiz',\n       's_aes_diagnosis_feedback', 's_aes_trigger_bryce_symptoms',\n       's_aes_trigger_teresa_symptoms', 's_aes_trigger_knowledge_quiz',\n       's_aes_trigger_diagnosis_feedback', 'action', 'action_name', 'done',\n       's_static_gender', 's_static_game_freq', 's_static_pretest', 'reward',\n       'state'],\n      dtype='object')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
